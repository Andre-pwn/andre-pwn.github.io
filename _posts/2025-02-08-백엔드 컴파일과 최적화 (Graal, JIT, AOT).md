---
title: 백엔드 컴파일과 최적화 (Graal, JIT, AOT)
authors: jongin_kim
date: 2025-02-08 00:00:00 +0900
categories: [JVM,JIT,AOT,Graal]
tags: [JVM,JIT,AOT,Graal]
---
# 백엔드 컴파일과 최적화 (Graal, JIT, AOT)

# 프런트엔드 컴파일, 백엔드 컴파일?

---

## 프런트엔드 컴파일

- 자바나 코틀린 같은 고수준언어를 JVM이 이해할 수 있는 바이트코드 (.class 파일) 로 변환하는 과정
- 보통 자바에서는 javac 를 실행하는 과정을 말함

## 백엔드 컴파일

- 바이트코드를 CPU나 OS에 맞게 네이티브 코드로 변환하는 과정
- 예를들면 JIT 컴파일러, AOT 컴파일러가 하는 역할
    - JIT는 런타임에 네이티브로 변환
        - JIT 자체는 빠르게 실행되지만, 최적화된 네이티브 코드가 생성되기까지 시간이 걸릴 수 있음
        - 하지만 런타임에 최적화 가능
    - AOT는 미리 컴파일 해두는 방식
        - 미리 변환해두기에 초기 실행 속도가 빠름
        - 런타임에 동적인 최적화 불가
- 백엔드 컴파일러는 그러므로 가상 머신의 성능을 좌우하는 주요 요소임
- 그래서 백엔드 컴파일러의 동작원리를 잘 파악하면 좋다
- JIT 컴파일 기준으로 설명하겠다

# 인터프리터의 또 다른 역할

---

- 일반적으로 자바의 컴파일 과정은 다음과 같다
- javac 컴파일 (프런트엔드 컴파일) → 바이트코드 (.class) → **인터프리팅 (컴파일이 아님)** → JIT 컴파일 (백엔드 컴파일) → 네이티브코드 (기계어/실행 가능한 바이너리)
- 당연히 인터프리팅 하는 과정은 컴파일이 아니다

### 인터프리터가 프로그램을 실행할 수 있나?

- 인터프리팅 단계에서는 아직 네티이브 코드가 만들어진 상황이 아니기 때문에 일반적으로는 실행할 수 없는게 맞다
- 하지만 JVM에서는 프로그램을 빠르게 시작하기 위해서 인터프리터가 먼저 나서서 백엔드 컴파일 없이 코드를 실행한다.
- CPU는 바이트코드를 이해할 수 없기 때문에 바이트코드로는 실행할 수 없는게 맞지만
- JVM이 바이트코드를 직접 해석하면서 실행할 수 있게 해준다.
- 물론 매번 해석해야하므로 속도가 매우 느리다
- 이 과정에서 자주 실행되는 코드나 성능에 문제가 있는 코드 (핫스팟)를 JIT가 네이티브로 변환해서 일종의 캐싱을 한다.
- 이 과정에서 변환된 네이티브 코드는 이후 다시 인터프리팅 혹은 변환을 할 필요 없이 바로 실행 가능

# 굳이 왜 동적 컴파일을 할까? (JIT)

---

- 그게 이제 AOT(Ahead-Of-Time) 컴파일과 JIT(Just-In-Time)의 차이고 장단점이 있음
- 굳이 AOT의 단점을 좀 더 이야기 해보자면 아래와 같음
    - 네이티브 코드는 CPU나 OS에 맞춰서 생성되기 때문에 OS, CPU 사양에 귀속되고 어디서나 실행할 수 없음
    - 진짜 필요한 코드만 네이티브화 하는게 아니라 싹다 컴파일
    - 리플렉션이나 다이나믹 프록시 같은 동적 로딩에 불리함
    - 모든 코드를 미리 컴파일 해야하므로 JIT에 비해서 컴파일 시간이 오래걸림

# JIT 컴파일러

---

## 최적화 취소

- 거의 그럴일은 없지만 가상 메서드 인라이닝 분석을 잘못한 경우, 클래스가 동적으로 로드되는 경우 등.. 이런 경우에는 최적화 취소 즉 다시 인터프리터에게 실행을 넘기는 경우가 생긴다
- 그래서 리플렉션이나 클래스 동적 생성 (newInstance()) 같은 코드들은 성능저하의 원인일 수 있음
    - JIT 최적화의 어려움, 최적화 취소 유발 등

## 클라이언트 컴파일러, 서버 컴파일러는 뭔데?

- 보통 HotSpot JVM에는 컴파일러가 2~3개 내장 되어있음
    - C1(Client Compiler): 빠르게 실행되지만 최적화 수준이 낮음
    - C2(Server Compiler): 컴파일 속도는 느리지만 최적화 수준이 높음
    - + JIT 컴파일러 (c2를 대체하는것을 목표로 함)
        - 기존의 C2 컴파일러는 강력한 최적화를 수행하지만, 유지보수의 한계에 봉착한듯
- 핫스팟 가상머신은 자체 버전과 머신의 성능에 맞춰 어떤 컴파일러를 사용할지 혹은 인터프리터만 사용할지 등 모드를 정할 수 있다
- 프로그램 시작 응답 속도, 인터프리터가 진행하는 성능 모니터링 및 해석 시간 등 여러가지 요인이 성능에 영향을 미칠 수 있기 때문에 최적의 균형을 맞춰야함
- 그렇기 때문에 1개의 컴파일러만 선택하는게 아닌 계층형 컴파일을 해야함

## 계층형 컴파일

- 핫스팟 JVM이 Client Compiler과 Server Compiler를 조합하여 최적의 성능을 내는 방식
- 처음부터 서버 컴파일을 하면 컴파일 시간, 실행 시간이 매우 느려지고, 반대의 경우는 또 반대로 문제
- 계층형 컴파일의 5단계
    - Tier 0 : 인터프리터 실행
    - Tier 1 ~ 3 : 클라이언트 컴파일
    - Tier 4 : 서버 컴파일
- 계층형 컴파일이 도입되면서 핫코드가 여러번 컴파일 될 수 있음

## 컴파일 대상과 컴파일 촉발 조건?

- JIT 컴파일러가 컴파일하는 대상을 핫코드라고 함
- 핫코드의 대표적인 유형
    - 여러 번 호출되는 메서드
    - 여러 번 실행되는 반복문의 본문
- 컴파일 대상은 개별 순환문의 본문만 하는건 아니고 메서드 전체를 컴파일 한다
- 여러번의 기준은? 뭐지? ⇒ 이게 바로 핫스팟 탐지
    - 카운터 기반 핫스팟 코드 탐지
    - 샘플 기반 핫스팟 탐지

### 카운터 기반 핫스팟 탐지

- OSR(On-Stack Replacement, 스택 교체 실행)은 JVM이 JIT 컴파일을 수행할 때 이미 실행 중인 메서드의 실행 상태를 유지하면서 즉시 최적화된 네이티브 코드로 전환하는 기술
- 핫스팟을 찾기 위해서 실행 횟수를 카운팅하는 방식
- 클라이언트, 서버 컴파일러 각각 기본 임계치가 설정되어있음
- 실행 횟수를 계속 유지해야하는 오버헤드가 있음
- 메서드 호출 카운터 (Invocation Counter)
    - 메서드 호출 횟수를 기록
    - 기본적으로는 메서드가 호출된 절대적인 횟수가 아니라 단위 시간당 호출 횟수를 계산함
    - 옵션에 따라 절대 횟수 기반으로 계산할 수 있게 할 수 있음
- 백 엣지 카운터 (Back Edge Counter)
    - Back Edge는 루프(loop)에서 반복을 수행할 때, 프로그램 실행 흐름이 되돌아가는 경로를 말한다.
    - 뱃엣지 횟수를 계산한다.
    - 이건 절대 실행 횟수를 계산한다

## 컴파일 과정

- 기본적으로 JIT 컴파일을 백그라운드에서 별도 스레드가 진행한다
- 컴파일이 완료될 때 까지는 인터프리터가 프로그램 실행을 이어간다

### 클라이언트 컴파일 과정

- 오래 걸리는 전역 최적화는 포기하고 지역 최적화에 초점
- HIR(고수준 중간 표현) LIR(저수준 중간 표현)은 JIT 컴파일 과정에서 코드 최적화를 수행하는 두 가지 주요 단계
- HIR
    - 고수준 최적화
    - 논리적인 코드 최적화 단계로 보면 된다.
    - 메서드 인라이닝, 루프 최적화, 상수 전파 등 고수준을 다룸
    - 여기까지는 클라이언트 컴파일
- LIR
    - 저수준 최적화
    - 하드웨어에 가까운 저수준 최적화
    - 레지스터 할당, 스택 프레임 관리 등
    - 메모리 접근을 최소화 하고, 레지스터 사용을 극대화
    - 백엔드 컴파일
- 전체적인 흐름은
    - 바이트코드 → HIR → LIR → 네이티브 코드
    - 라고 보면 된다

> 여기서 중요한건 클라이언트, 서버 컴파일과
프런트엔드 백엔드 컴파일은 다른 개념이다.
클라이언트 컴파일 과정에서도 프런트엔드, 백엔드 컴파일은 나눠진다.
> 

### 서버 컴파일 과정

- 상당히 복잡한 최적화를 지원하는 고급 컴파일

### 레지스터 할당?

- 레지스터는 CPU에서 가장 빠르게 데이터를 읽고 쓸 수 있는 저장 공간
    - 즉 CPU에서 가장 빠른 메모리
    - JIT 컴파일러가 최적화할 때 가장 신경 쓰는 부분이 레지스터를 얼마나 효율적으로 사용하는가
    - CPU의 성능을 극대화하려면, 가능한 많은 연산을 레지스터에서 수행하는 것이 필수적
- CPU 레지스터의 개수는 제한되어있으니 어떤 변수를 레지스터 할당을 할지 판단하는게 매우 중요함
- JIT는 그래서 자주 사용되는 변수나 코드를 레지스터에 할당하려고 노력하는 것
    - 그렇지 않은 변수는 메모리(RAM)에 보내는것
- 결국 레지스터 활용 극대화 및 할당은 컴파일러의 가장 중요한 성능개선 요소 중 하나인 것

# 컴파일 결과 및 과정 직접 확인하기?

---

- 메서드 이름만 확인
    - 가상머신 printCompilation 옵션을 사용하면 JIT 컴파일러가 네이티브 코드로 컴파일한 메서드의 이름을 보여준다.
    - 메서드 이름이 중복으로 보일 수 있다.
    - 실제로 클라이언트, 서버, 최적화 취소 등 과정으로 여러번 컴파일 할 수 있기 때문에
- 메서드 이름을 떠나서 실제로 컴파일러가 생성한 네이티브코드 확인
    - 네이티브 코드에는 0,1의 기계어가 포함되어있는데 우리가 알아보기 힘들기 때문에 어셈블리어로 변환해서 보는게 좋고 매개변수 설정을 통해 어셈블리 코드로 볼 수 있다.
- IGV(Ideal Graph Visualizer)란
    - JIT 컴파일러가 생성한 내부 최적화 그래프를 시각적으로 분석할 수 있는 도구
    - JVM이 이 코드를 어떻게 최적화 하는지 확인 할수 있다

# AOT 컴파일러

---

- 자바는 한 번 작성하면 어디서든 실행된다 라는 컨셉이 있었기에 처음엔 주목받지 못했음
- 주목 받게 되는 주요 사례
    - 안드로이드가 달빅 VM 과 JIT 컴파일러를 사용했는데 배터리 소모와 성능 저하문제가 심각했고
        - 롤리팝 버전 부터 AOT방식의 컴파일이 도입되면서 (ART 안드로이드 런타임) 앱 설치시 네이티브 코드로 변환하도록 하고 배터리나 CPU 사용량을 절약할 수 있었다
        - 앱 실행속도와 배터리 효율 매우 증가
    - 유니티, 언리얼 엔진 같은 게임 엔진
        - 프레임 드롭 방지를 위해 CPU 사용량 최적화가 필요했고 JIT 오버헤드를 줄이고 AOT 방식으로 개선
    - IOS의 보안정책
        - IOS는 보안 정책상 JIT 컴파일 자체가 허용되지 않는다
            - 런타임 컴파일 자체가 금지되어있는 듯?
        - W^X(Write XOR Execute) 보안 정책 (쓰기 또는 실행 정책)
            - [https://en.wikipedia.org/wiki/W^X](https://en.wikipedia.org/wiki/W%5EX)
            - 메모리가 쓰기, 실행 모두 가능하지만 동시에는 안된다
    - 서버리스 환경
        - aws 람다 같은 애들은 서버리스고 제품 특성상 워밍업 시간이 매우 단축되어야한다
        - 그래서 JIT방식 보다는 미리 네이티브 코드를 만들어두는 AOT 방식 선호
- 방식
    - 프로그램이 실행하기 전에 코드를 네이티브 코드로 컴파일 하는 방법
    - JIT 컴파일러가 런타임에 수행해야 한느 작업을 미리 수행해 캐싱해두고 다음 실행시에 재사용하는 방법
        - 동적 AOT 또는 JIT 캐싱 이라고 함
        - 공통 라이브러리 코드 같은 것들을

## JIT 컴파일러가 AOT 컴파일러보다 나은점?

- 성능 모니터링 기반 최적화
- 급진적 예측 최적화
    - AOT 처럼 보수적으로 컴파일 할 필요가 없다 100% 정확하지는 않아도 성능 모니터링 정보를 토대로 높은 확률로 정확한 판단을 할 수 있다.
    - 높은 가능성을 기반으로 판단을 하고 과감하게 최적화하는 것
- 링크 타임 최적화
    - 개별 컴파일 코드를 하나로 링킹(연결)하면서 최적화를 수행하는 기법을 링크 타임 최적화라고 하는데
    - JIT는 런타임에 네이티브 코드를 생성하니깐 링크 타임 직전에 최적화를 수행할 수 있는 기회를 갖는다
        - AOT는 컴파일시에 링크 타임이 일어나고 최적화에 불리하다

# 컴파일러의 최적화 기법

---

- openjdk에 소개된 JIT컴파일러가 이용하는 최적화 기법들
- [https://wiki.openjdk.org/display/HotSpot/PerformanceTacticIndex](https://wiki.openjdk.org/display/HotSpot/PerformanceTacticIndex)

많지만 4개만 소개

- 메서드 인라인
- 탈출 분석
- 공통 하위 표현식 제거
- 배열 경계 검사 제거

## 메서드 인라인

- 메서드 호출 비용을 없앤다
- 다른 최적화를 적용하기 쉽도록 길을 미리 평탄하게 한다
- 가상메서드
    - 실행중에 어떤 메서드를 호출할지 정해지는 메서드
    - 자바의 다형성의 핵심요소 중 하나라고 볼 수 있고, 자바의 메서드는 대부분 가상메서드다
    - 실제로 실행될때 결정되어야하므로 컴파일시점에 100% 예측 후 인라이닝 하기 어렵다
    - 그렇다고 실행 성능을 높이려고 모든 메소드에 final을 달아야할까?
    - 그래서 자바는 계층구조 분석을 해 후보군을 좁히고 동적으로 급진적 예측을 한다
    - 예측에 실패하면 최적화 취소를 하고 재컴파일 한다
- 그래서 자바에서 메서드 인라인은 보통은 급진적 최적화다

## 탈출 분석

- 객체가 메서드 내부에서만 사용되는 경우 힙이 아닌 스택에 할당해 GC 부담을 줄인다
- 탈출하지 않는 객체 = 스택에 할당 가능 = 메모리 최적화 가능
- 탈출 종류
    - 전역탈출
        - 객체가 메서드 외부로 전달되거나 전역번수인 경우 객체의 수명을 예측할 수 없기에 힙에 할당해야함
    - 인수탈출
        - 객체가 메서드의 파라미터로 전달되었지만 메서드 외부에서 직접 접근하지 않는 경우
        - 객체가 다른 메서드에 의해서 또 참조될 수 있어서 힙에 할당이 필요할 수 도 있다
    - 탈출하지 않음
        - 객체가 메서드 내부에서만 사용되고 외부로 전달 안되는 경우
        - 스택에 할당 가능
- 스택할당이 더 효율적인 이유
    - 힙에 비해서 메모리 접근 속도가 더 빠름
        - 레지스터에 할당될 가능성이 높음
    - GC 부담
        - GC를 하기위해서 주기적으로 탐색하고 제거하는 성능저하가 없음
        - 메소드가 종료되면 자동으로 제거됨
- 스칼라 치환
    - 스칼라 변수 : int, long과 같이 더이상 작게 분해할 수 없는 데이터
    - 집합체 (객체) : 더 작게 분해할 수 있는 데이터
    - 객체가 내부에서만 사용된다고 판단이 되면 스칼라변수로 치환 (분해) 해서 힙 할당을 피하고, 스택이나 레지스터에서 처리하도록 유도
- 동기화 제거
    - 동기화는 그 자체로 매우 부하가 큰 작업
    - 탈출이 일어나지 않는다고 판단하면 불필요한 동기화는 제거함
    - 동시성 문제도 해소 (synchronized)
- 탈출 분석이 실질적으로 효용성이 떨어지는 이유
    - 이론적으로 매우 유용한 최적화 기법이지만, 현실적으로는 몇 가지 이유로 인해 효율성이 떨어짐
    - 전역탈출이나, 탈출하지 않는 경우도 있지만 대부분은 인수탈출 처럼 명확하게 판단하기 어려움
    - 인라이닝을 하면 최적화 과정에서 스택할당이 불가능해진다거나 .. 다른 최적화 기법과의 충돌

## 공통 하위 표현식 제거

- 공통 하위 표현식
    - 표현식 E 가 이미 평가되었고 E에 등장하는 모든 변수값이 평가 이후 변하지 않는다면
    - 뒤에 등장하는 E를 공통 하위 표현식이라고 함
- 같은 연산을 반복 수행하지 않고, 한번만 계산한 후 재사용하는 최적화 기법
- 불필요한 연산을 줄여 CPU 사용량을 절감한다

## 배열 경계 검사 제거

- 배열 인덱스가 항상 유효한 범위 내에 있다는 것이 보장되는 경우 불필요한 경계 검사를 제거하는 방법
- 배열 접근 속도가 매우 향상 됨

# Graal 컴파일러

---

- 전통적인 클라이언트, 서버 컴파일러가 아니라 Graal 컴파일러를 활용한 컴파일러를 이야기 해보겠다
- JIT과 AOT 컴파일 모두 지원한다
- 기존 컴파일러랑 다르게 JAVA로 작성이 되었고
- c2 컴파일러는 더이상 유지보수가 힘들다고 판단함
- 컴파일러 인터페이스 (JVMCI) 덕분에 수월해짐
    - 기존 JIT 컴파일러(c1,c2)는 JVM 내부에 C++로 구현되어있었는데
    - C++로 작성되어서 유지보수도 힘들었고 직접 JVM 내부 코드를 수정했어야 함
    - 하지만 JDK9에 포함된 JVM과 JIT 컴파일러간 표준 인터페이스 덕분에 JVM을 직접 수정하지 않아도 새로운 JIT 컴파일러를 추가할 수 있었음
    - JAVA로 작성된 JIT 컴파일러 (Graal)도 JVM에서 실행 가능해짐
    
    ```java
    import jdk.vm.ci.meta.*;
    import jdk.vm.ci.hotspot.*;
    import jdk.vm.ci.code.*;
    ```
    

## 빌드 도구 MX

- mx 는 GraalVM 및 관련 프로젝트를 빌드하고 관리하는 전용 빌드 도구
- 일반적인 빌드 도구(Maven, Gradle)와는 달리 GraalVM의 네이티브 컴파일 환경과 JIT 컴파일러 개발에 최적화되어 있음
- JIT 컴파일러, AOT 컴파일러를 쉽게 빌드하고 실행할 수 있도록 함

## 아이디얼 그래프

- Graal 컴파일러도 핫스팟 컴파일러와 매우 비슷한 중간 표현을 사용하도록 설계되었다
- 아이디얼 그래프를 시각적으로 분석할 수 있는 도구가 Ideal Graph Visualizer(IGV)
    - IGV를 사용하면, Graal JIT이 바이트코드를 어떻게 최적화하는지 확인 가능
- 순서
    - Java 바이트코드 → 아이디얼 그래프 생성
    - 그래프 기반 최적화 수행 (메서드 인라이닝, 상수 전파, 루프 최적화 등)
    - 그래프를 기계어(네이티브 코드)로 변환
    - 최적화된 네이티브 코드 실행
- 즉, 아이디얼 그래프는 단순한 바이트코드를 네이티브 코드로 변환하기 전에 최적화할 수 있도록 돕는 핵심 구조
- 아이디얼 그래프 예시
    - 각 블록이 특정 연산을 수행하는 노드(Node)를 나타냄
    - 화살표(Edge)는 데이터 및 제어 흐름을 의미
    - Graal은 이 그래프를 변형하며 최적화를 수행
